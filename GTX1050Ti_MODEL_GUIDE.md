# üéØ GPU Model Recommendations - GTX 1050 Ti

## üìä Th√¥ng tin GPU c·ªßa b·∫°n

```
GPU: NVIDIA GeForce GTX 1050 Ti
VRAM: 4.29 GB
CUDA: 12.1
Compute Capability: 6.1
Status: ‚úÖ GPU ho·∫°t ƒë·ªông t·ªët!
```

---

## üèÜ KHUY·∫æN NGH·ªä MODEL

### ‚≠ê Model `small` - KHUY·∫æN NGH·ªä NH·∫§T

```powershell
python audio_video_processor.py actors.mp3 --model small --device cuda
```

**T·∫°i sao ch·ªçn `small`:**
- ‚úÖ VRAM: 2 GB (an to√†n v·ªõi GPU 4.29 GB)
- ‚úÖ ƒê·ªô ch√≠nh x√°c: R·∫•t t·ªët (‚≠ê‚≠ê‚≠ê‚≠ê)
- ‚úÖ T·ªëc ƒë·ªô: Nhanh (8-10s cho 1 ph√∫t audio)
- ‚úÖ **C√¢n b·∫±ng ho√†n h·∫£o cho GTX 1050 Ti**
- ‚úÖ Ph√π h·ª£p cho app h·ªçc ti·∫øng Anh

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
Transcribing 1 ph√∫t audio:
- CPU: ~60 gi√¢y
- GPU (small): ~8-10 gi√¢y
‚Üí Nhanh h∆°n 6-7x ‚ö°
```

---

### ‚úÖ Model `base` - AN TO√ÄN NH·∫§T

```powershell
python audio_video_processor.py actors.mp3 --model base --device cuda
```

**Khi n√†o d√πng:**
- Mu·ªën ch·∫Øc ch·∫Øn 100% kh√¥ng b·ªã l·ªói
- X·ª≠ l√Ω audio d√†i (>30 ph√∫t)
- Batch processing nhi·ªÅu file
- C·∫ßn t·ªëc ƒë·ªô nhanh nh·∫•t

**ƒê·∫∑c ƒëi·ªÉm:**
- VRAM: 1 GB (r·∫•t an to√†n)
- ƒê·ªô ch√≠nh x√°c: T·ªët (‚≠ê‚≠ê‚≠ê)
- T·ªëc ƒë·ªô: R·∫•t nhanh (3-5s cho 1 ph√∫t audio)

**K·∫øt qu·∫£ mong ƒë·ª£i:**
```
Transcribing 1 ph√∫t audio:
- CPU: ~20 gi√¢y
- GPU (base): ~3-5 gi√¢y
‚Üí Nhanh h∆°n 4-6x ‚ö°
```

---

### ‚ö†Ô∏è Model `medium` - C√ì TH·ªÇ TH·ª¨ (Risk)

```powershell
python audio_video_processor.py actors.mp3 --model medium --device cuda
```

**L∆ØU √ù:**
- ‚ùó VRAM: 5 GB (v∆∞·ª£t qu√° 4.29 GB c·ªßa b·∫°n)
- ‚ö†Ô∏è **C√≥ th·ªÉ b·ªã "CUDA out of memory"**
- Ch·ªâ th·ª≠ v·ªõi audio ng·∫Øn (<5 ph√∫t)
- ƒê√≥ng t·∫•t c·∫£ app kh√°c tr∆∞·ªõc khi ch·∫°y

**N·∫øu b·ªã l·ªói OOM:**
```powershell
# Quay v·ªÅ small
python audio_video_processor.py actors.mp3 --model small --device cuda
```

**K·∫øt qu·∫£ n·∫øu ch·∫°y ƒë∆∞·ª£c:**
```
Transcribing 1 ph√∫t audio:
- CPU: ~180 gi√¢y
- GPU (medium): ~20-25 gi√¢y
‚Üí Nhanh h∆°n 7-9x ‚ö°
```

---

### ‚ùå Model `large` - KH√îNG D√ôNG ƒê∆Ø·ª¢C

```
VRAM c·∫ßn: 10 GB
VRAM c√≥: 4.29 GB
‚Üí Ch·∫Øc ch·∫Øn out of memory ‚ùå
```

---

## üìä B·∫¢NG SO S√ÅNH CHI TI·∫æT

| Model | VRAM | GTX 1050 Ti | T·ªëc ƒë·ªô/ph√∫t | ƒê·ªô ch√≠nh x√°c | Use case |
|-------|------|-------------|-------------|--------------|----------|
| **tiny** | 1 GB | ‚úÖ R·∫•t t·ªët | ~2s | ‚≠ê‚≠ê | Test nhanh |
| **base** | 1 GB | ‚úÖ **An to√†n** | **~3-5s** | ‚≠ê‚≠ê‚≠ê | **H√†ng ng√†y** |
| **small** | 2 GB | ‚úÖ **T·ªët nh·∫•t** | **~8-10s** | ‚≠ê‚≠ê‚≠ê‚≠ê | **KHUY·∫æN NGH·ªä** |
| medium | 5 GB | ‚ö†Ô∏è Risk OOM | ~20-25s | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Th·ª≠ ƒë∆∞·ª£c |
| large | 10 GB | ‚ùå Kh√¥ng ƒë·ªß | N/A | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Kh√¥ng d√πng |

---

## üéØ KHUY·∫æN NGH·ªä CHO C√ÅC USE CASE

### Use Case 1: App h·ªçc ti·∫øng Anh (Dictation & Shadowing)

```powershell
# D√πng SMALL - ƒê·ªô ch√≠nh x√°c cao quan tr·ªçng
python audio_video_processor.py lesson_audio.mp3 --model small --device cuda
```

**L√Ω do:**
- Transcription ch√≠nh x√°c quan tr·ªçng cho h·ªçc ng√¥n ng·ªØ
- T·ªëc ƒë·ªô ƒë·ªß nhanh (8-10s/ph√∫t)
- ·ªîn ƒë·ªãnh, kh√¥ng lo OOM
- Ch·∫•t l∆∞·ª£ng t·ªët cho user experience

---

### Use Case 2: Batch processing nhi·ªÅu file

```powershell
# D√πng BASE - T·ªëc ƒë·ªô ∆∞u ti√™n
python audio_video_processor.py audio.mp3 --model base --device cuda
```

**L√Ω do:**
- X·ª≠ l√Ω nhanh nh·∫•t (3-5s/ph√∫t)
- An to√†n v·ªõi m·ªçi k√≠ch th∆∞·ªõc audio
- Suitable cho processing h√†ng lo·∫°t
- Ti·∫øt ki·ªám th·ªùi gian

**Example batch script:**
```python
from audio_video_processor import AudioVideoProcessor

processor = AudioVideoProcessor(model_size="base", device="cuda")

audio_files = ["file1.mp3", "file2.mp3", "file3.mp3"]

for audio in audio_files:
    print(f"Processing: {audio}")
    result = processor.process(audio)
    print(f"Done: {result['total_sentences']} sentences")
```

---

### Use Case 3: Audio ng·∫Øn, c·∫ßn ƒë·ªô ch√≠nh x√°c cao

```powershell
# TH·ª¨ MEDIUM (risk nh∆∞ng worth it)
python audio_video_processor.py short_audio.mp3 --model medium --device cuda
```

**ƒêi·ªÅu ki·ªán:**
- Audio < 5 ph√∫t
- ƒê√≥ng t·∫•t c·∫£ app kh√°c
- Monitor GPU memory: `nvidia-smi`

**N·∫øu l·ªói OOM:**
```powershell
# Fallback v·ªÅ SMALL
python audio_video_processor.py short_audio.mp3 --model small --device cuda
```

---

## üí° TIPS T·ªêI ∆ØU GPU

### 1. Gi·∫£i ph√≥ng VRAM tr∆∞·ªõc khi ch·∫°y

```powershell
# Check VRAM usage
nvidia-smi

# ƒê√≥ng c√°c app ƒÉn VRAM:
# - Google Chrome (nhi·ªÅu tabs)
# - Games
# - Video editors (Premiere, DaVinci)
# - 3D software (Blender, Unity)
```

### 2. Ch·ªçn model theo ƒë·ªô d√†i audio

```powershell
# Audio < 5 ph√∫t ‚Üí Th·ª≠ MEDIUM
python audio_video_processor.py short.mp3 --model medium --device cuda

# Audio 5-30 ph√∫t ‚Üí D√πng SMALL
python audio_video_processor.py medium.mp3 --model small --device cuda

# Audio > 30 ph√∫t ‚Üí D√πng BASE
python audio_video_processor.py long.mp3 --model base --device cuda
```

### 3. Monitor GPU trong khi ch·∫°y

```powershell
# Terminal 1: Ch·∫°y processing
python audio_video_processor.py audio.mp3 --model small --device cuda

# Terminal 2: Monitor GPU
nvidia-smi -l 1  # Update m·ªói 1 gi√¢y
```

### 4. Batch processing hi·ªáu qu·∫£

```python
# ‚úÖ ƒê√öNG: Load model 1 l·∫ßn, d√πng nhi·ªÅu l·∫ßn
processor = AudioVideoProcessor(model_size="small", device="cuda")
for audio in audio_files:
    result = processor.process(audio)

# ‚ùå SAI: Load model l·∫°i cho m·ªói file (ch·∫≠m)
for audio in audio_files:
    processor = AudioVideoProcessor(model_size="small", device="cuda")
    result = processor.process(audio)
```

---

## üß™ TESTING MODELS

### Script ƒë·ªÉ test t·∫•t c·∫£ models

T·∫°o file `test_models.py`:

```python
import time
from audio_video_processor import AudioVideoProcessor

test_audio = "actors.mp3"  # Thay b·∫±ng file c·ªßa b·∫°n
models = ["tiny", "base", "small"]  # Kh√¥ng test medium/large

print("="*60)
print("MODEL PERFORMANCE TEST - GTX 1050 Ti")
print("="*60)

for model in models:
    print(f"\nüß™ Testing model: {model}")
    
    try:
        start_time = time.time()
        processor = AudioVideoProcessor(
            model_size=model, 
            device="cuda",
            output_dir=f"output_{model}"
        )
        
        result = processor.process(test_audio)
        
        elapsed = time.time() - start_time
        
        print(f"‚úÖ Success!")
        print(f"   Time: {elapsed:.2f}s")
        print(f"   Sentences: {result['total_sentences']}")
        print(f"   Speed: {elapsed/60:.2f}s per minute of audio")
        
    except Exception as e:
        print(f"‚ùå Failed: {e}")

print("\n" + "="*60)
print("TEST COMPLETE")
print("="*60)
```

Ch·∫°y:
```powershell
python test_models.py
```

---

## üìà K·∫æT QU·∫¢ D·ª∞ KI·∫æN

### Audio 1 ph√∫t

| Model | CPU Time | GPU Time | Speed Up |
|-------|----------|----------|----------|
| tiny  | 10s      | ~2s      | 5x       |
| **base** | 20s | **~3-5s** | **4-6x** |
| **small** | 60s | **~8-10s** | **6-7x** |
| medium* | 180s | ~20-25s* | 7-9x* |

*medium: C√≥ th·ªÉ OOM

### Audio 10 ph√∫t

| Model | CPU Time | GPU Time | Speed Up |
|-------|----------|----------|----------|
| base  | 3m 20s   | ~30-50s  | 4-6x     |
| small | 10m      | ~80-100s | 6-7x     |

### Audio 1 gi·ªù

| Model | CPU Time | GPU Time | Khuy·∫øn ngh·ªã |
|-------|----------|----------|-------------|
| base  | 20m      | ~3-5m    | ‚úÖ An to√†n |
| small | 60m      | ~8-10m   | ‚ö†Ô∏è OK nh∆∞ng base nhanh h∆°n |

---

## ‚ö†Ô∏è X·ª¨ L√ù L·ªñI

### L·ªói: "CUDA out of memory"

```
RuntimeError: CUDA out of memory. Tried to allocate X MB
```

**Gi·∫£i ph√°p:**

```powershell
# 1. D√πng model nh·ªè h∆°n
python audio_video_processor.py audio.mp3 --model base --device cuda

# 2. Ho·∫∑c d√πng CPU cho model l·ªõn
python audio_video_processor.py audio.mp3 --model medium --device cpu

# 3. Gi·∫£i ph√≥ng GPU memory
nvidia-smi  # Check process ƒëang d√πng GPU
# Kill c√°c process kh√¥ng c·∫ßn thi·∫øt
```

### L·ªói: "GPU computation failed"

```powershell
# Ki·ªÉm tra GPU
nvidia-smi

# Reinstall PyTorch
pip uninstall torch torchaudio -y
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# Test l·∫°i
python test_gpu.py
```

### Warning: "FP16 is not supported on CPU"

```
ƒê√¢y KH√îNG ph·∫£i l·ªói, ch·ªâ l√† warning.
Whisper t·ª± ƒë·ªông chuy·ªÉn sang FP32.
C√≥ th·ªÉ ignore.
```

---

## üéØ FINAL RECOMMENDATION

### Cho GTX 1050 Ti (4.29 GB VRAM):

**üèÜ Best choice: Model `small`**

```powershell
python audio_video_processor.py audio.mp3 --model small --device cuda
```

**L√Ω do:**
1. ‚úÖ ƒê·ªô ch√≠nh x√°c cao (‚≠ê‚≠ê‚≠ê‚≠ê) - T·ªët cho app h·ªçc ti·∫øng Anh
2. ‚úÖ T·ªëc ƒë·ªô nhanh (8-10s/ph√∫t) - Acceptable cho production
3. ‚úÖ An to√†n (2 GB VRAM) - Kh√¥ng lo OOM
4. ‚úÖ C√¢n b·∫±ng ho√†n h·∫£o

**Alternative: Model `base`**
- N·∫øu c·∫ßn t·ªëc ƒë·ªô c·ª±c nhanh
- N·∫øu x·ª≠ l√Ω audio r·∫•t d√†i
- N·∫øu ƒë·ªô ch√≠nh x√°c kh√¥ng qu√° critical

---

## üìä T√ìM T·∫ÆT QUICK REFERENCE

```powershell
# Khuy·∫øn ngh·ªã chung (Best balance)
python audio_video_processor.py audio.mp3 --model small --device cuda

# Nhanh nh·∫•t (Safe & Fast)
python audio_video_processor.py audio.mp3 --model base --device cuda

# Ch√≠nh x√°c nh·∫•t c√≥ th·ªÉ (Risk OOM)
python audio_video_processor.py audio.mp3 --model medium --device cuda

# Fallback n·∫øu OOM
python audio_video_processor.py audio.mp3 --model small --device cuda
```

---

## ‚úÖ CHECKLIST

- [x] GPU detected: GTX 1050 Ti
- [x] VRAM: 4.29 GB
- [x] CUDA: 12.1
- [x] PyTorch with CUDA installed
- [ ] Tested model `base` ‚Üí Should work ‚úÖ
- [ ] Tested model `small` ‚Üí **Recommended** ‚úÖ
- [ ] Tested model `medium` ‚Üí Optional (may OOM) ‚ö†Ô∏è

---

## üìö RELATED FILES

- [audio_video_processor.py](computer:///mnt/user-data/outputs/audio_video_processor.py) - Main script with GPU support
- [test_gpu.py](computer:///mnt/user-data/outputs/test_gpu.py) - GPU test script
- [GPU_SETUP.md](computer:///mnt/user-data/outputs/GPU_SETUP.md) - Complete GPU setup guide
- [GPU_QUICKSTART.md](computer:///mnt/user-data/outputs/GPU_QUICKSTART.md) - Quick setup guide

---

**Created:** November 26, 2024  
**GPU:** NVIDIA GeForce GTX 1050 Ti (4.29 GB)  
**Recommended Model:** `small` üèÜ  
**Alternative:** `base` (faster but less accurate)
