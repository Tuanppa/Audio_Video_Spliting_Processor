# üî¨ Advanced Processor - Terminal Usage & VAD Explained

## ‚ö†Ô∏è QUAN TR·ªåNG: KH√îNG C√ì COMMAND LINE BUILT-IN!

**`advanced_processor.py` KH√îNG c√≥ command line interface nh∆∞ `audio_video_processor.py`!**

```powershell
# ‚ùå KH√îNG WORK
python advanced_processor.py audio.mp3  # ‚Üê Kh√¥ng c√≥ CLI n√†y!

# ‚úÖ PH·∫¢I D√ôNG CODE
python your_script.py  # Script v·ªõi Python code
```

---

## üõ†Ô∏è GI·∫¢I PH√ÅP: T·∫†O WRAPPER SCRIPT

### T·∫°o file `run_advanced.py`:

```python
"""
Wrapper script ƒë·ªÉ ch·∫°y advanced_processor.py t·ª´ terminal
"""
import argparse
from advanced_processor import AdvancedAudioProcessor, batch_process_folder

def main():
    parser = argparse.ArgumentParser(
        description='Advanced Audio/Video Processor with VAD'
    )
    
    # Positional arguments
    parser.add_argument('input', help='Path to audio/video file or folder')
    
    # Optional arguments
    parser.add_argument('--batch', '-b', action='store_true',
                       help='Batch process folder')
    parser.add_argument('--model', '-m', default='small',
                       choices=['tiny', 'base', 'small', 'medium', 'large'],
                       help='Whisper model size (default: small)')
    parser.add_argument('--device', '-d', default=None,
                       choices=['cuda', 'cpu'],
                       help='Device to use (default: auto-detect)')
    parser.add_argument('--output', '-o', default='advanced_output',
                       help='Output directory (default: advanced_output)')
    
    # Advanced features
    parser.add_argument('--vad', action='store_true',
                       help='Enable Voice Activity Detection')
    parser.add_argument('--normalize', '-n', action='store_true',
                       help='Normalize audio volume')
    parser.add_argument('--formats', nargs='+',
                       default=['json', 'srt'],
                       choices=['json', 'srt', 'txt', 'csv'],
                       help='Export formats (default: json srt)')
    
    # Video/YouTube
    parser.add_argument('--video', '-v', action='store_true',
                       help='Input is video file')
    parser.add_argument('--youtube', '-y', action='store_true',
                       help='Input is YouTube URL')
    
    args = parser.parse_args()
    
    # Batch processing
    if args.batch:
        print(f"Batch processing folder: {args.input}")
        batch_process_folder(
            folder_path=args.input,
            output_base=args.output,
            model_size=args.model,
            device=args.device
        )
    else:
        # Single file processing
        print(f"Processing file: {args.input}")
        
        processor = AdvancedAudioProcessor(
            output_dir=args.output,
            model_size=args.model,
            device=args.device
        )
        
        result = processor.process_advanced(
            args.input,
            is_youtube=args.youtube,
            is_video=args.video,
            use_vad=args.vad,
            normalize=args.normalize,
            export_formats=args.formats
        )
        
        print(f"\n‚úÖ Processing complete!")
        print(f"   Sentences: {result['statistics']['total_sentences']}")
        print(f"   Duration: {result['statistics']['total_duration']:.2f}s")
        print(f"   Export files: {list(result['export_files'].keys())}")

if __name__ == "__main__":
    main()
```

---

## üöÄ C√ö PH√ÅP TERMINAL (Sau khi t·∫°o wrapper)

### 1. Basic Processing

```powershell
# ƒê∆°n gi·∫£n
python run_advanced.py audio.mp3

# V·ªõi model v√† device
python run_advanced.py audio.mp3 --model small --device cuda
```

---

### 2. With VAD + Normalize

```powershell
# Enable VAD v√† normalize
python run_advanced.py audio.mp3 --vad --normalize

# Vi·∫øt t·∫Øt
python run_advanced.py audio.mp3 --vad -n
```

---

### 3. Custom Export Formats

```powershell
# T·∫•t c·∫£ formats
python run_advanced.py audio.mp3 --formats json srt txt csv

# Ch·ªâ TXT
python run_advanced.py audio.mp3 --formats txt
```

---

### 4. Complete Features

```powershell
# T·∫•t c·∫£ features
python run_advanced.py audio.mp3 \
    --model small \
    --device cuda \
    --vad \
    --normalize \
    --formats json srt txt csv \
    --output my_output
```

---

### 5. Video File

```powershell
python run_advanced.py video.mp4 --video --vad -n
```

---

### 6. YouTube URL

```powershell
python run_advanced.py "https://youtube.com/watch?v=xxx" --youtube --vad
```

---

### 7. Batch Processing

```powershell
# Batch process folder
python run_advanced.py audio_folder --batch --model small --device cuda

# V·ªõi output directory
python run_advanced.py audio_folder --batch --output batch_results
```

---

## üìä T·∫§T C·∫¢ PARAMETERS

```powershell
python run_advanced.py [INPUT] [OPTIONS]

Positional Arguments:
  input                 Path to audio/video file or folder

Required for specific modes:
  --batch, -b          Batch process folder
  --video, -v          Input is video file
  --youtube, -y        Input is YouTube URL

Model & Device:
  --model, -m          Model size: tiny/base/small/medium/large (default: small)
  --device, -d         Device: cuda/cpu (default: auto-detect)
  --output, -o         Output directory (default: advanced_output)

Advanced Features:
  --vad                Enable Voice Activity Detection
  --normalize, -n      Normalize audio volume
  --formats            Export formats: json/srt/txt/csv (default: json srt)

Examples:
  python run_advanced.py audio.mp3
  python run_advanced.py audio.mp3 --vad --normalize
  python run_advanced.py audio.mp3 --formats json srt txt csv
  python run_advanced.py audio_folder --batch --model small --device cuda
  python run_advanced.py video.mp4 --video --vad
  python run_advanced.py "https://youtube.com/..." --youtube
```

---

## üîç VAD - TH∆ØVI·ªÜN ƒê·∫∂C BI·ªÜT

### Advanced Processor s·ª≠ d·ª•ng g√¨ kh√°c bi·ªát?

**Core Processor (`audio_video_processor.py`):**
```python
# Ch·ªâ d√πng:
- Whisper (transcription)
- Pattern-based sentence detection (regex: [.!?])
- Pydub (audio manipulation c∆° b·∫£n)
```

**Advanced Processor (`advanced_processor.py`):**
```python
# Th√™m:
‚úÖ Pydub.silence module (VAD - Voice Activity Detection)
   - detect_nonsilent()
   - split_on_silence()
‚úÖ Audio normalization (pydub effects)
‚úÖ Silence detection algorithms
```

---

### Chi ti·∫øt VAD trong Advanced Processor

**Th∆∞ vi·ªán s·ª≠ d·ª•ng:**
```python
from pydub.silence import detect_nonsilent, split_on_silence
```

**Kh√¥ng ph·∫£i AI/ML model!** VAD trong advanced_processor d·ª±a tr√™n:
- **Amplitude-based detection**: Ph√¢n t√≠ch volume (dBFS)
- **Threshold-based**: So s√°nh v·ªõi ng∆∞·ª°ng silence_thresh
- **Simple signal processing**: Kh√¥ng d√πng neural networks

---

### C√°ch ho·∫°t ƒë·ªông c·ªßa VAD

```python
# detect_nonsilent()
segments = detect_nonsilent(
    audio,
    min_silence_len=500,    # Silence t·ªëi thi·ªÉu 500ms
    silence_thresh=-40      # √Çm l∆∞·ª£ng < -40 dBFS = silence
)
```

**Thu·∫≠t to√°n:**
1. Qu√©t audio t·ª´ ƒë·∫ßu ƒë·∫øn cu·ªëi
2. ƒêo amplitude (volume) c·ªßa m·ªói chunk (th∆∞·ªùng 10ms)
3. N·∫øu amplitude < silence_thresh ‚Üí ƒê√°nh d·∫•u l√† silence
4. N·∫øu silence k√©o d√†i >= min_silence_len ‚Üí T√°ch ƒëo·∫°n
5. Return c√°c segments kh√¥ng ph·∫£i silence

**V√≠ d·ª•:**
```
Audio: [voice]----silence----[voice]--[voice]----silence----[voice]
            ‚Üë         ‚Üë         ‚Üë        ‚Üë          ‚Üë          ‚Üë
         Start1    End1      Start2   End2      Start3     End3

Returns: [(Start1, End1), (Start2, End2), (Start3, End3)]
```

---

### So s√°nh v·ªõi ML-based VAD

**PyDub VAD (Advanced processor d√πng):**
- ‚úÖ ƒê∆°n gi·∫£n, nhanh
- ‚úÖ Kh√¥ng c·∫ßn train
- ‚úÖ CPU-friendly
- ‚ùå K√©m ch√≠nh x√°c v·ªõi noise
- ‚ùå Kh√¥ng ph√¢n bi·ªát speech vs music
- ‚ùå Sensitive to threshold tuning

**ML-based VAD (WebRTC VAD, Silero VAD):**
- ‚úÖ Ch√≠nh x√°c h∆°n nhi·ªÅu
- ‚úÖ Robust v·ªõi noise
- ‚úÖ Ph√¢n bi·ªát ƒë∆∞·ª£c speech
- ‚ùå Ph·ª©c t·∫°p h∆°n
- ‚ùå C·∫ßn model files
- ‚ùå Ch·∫≠m h∆°n

---

### N·∫øu mu·ªën ML-based VAD t·ªët h∆°n

**Option 1: Silero VAD** (Recommended)

```python
# Install
pip install silero-vad

# Usage
import torch
model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                              model='silero_vad')
(get_speech_timestamps, _, read_audio, *_) = utils

wav = read_audio('audio.wav')
speech_timestamps = get_speech_timestamps(wav, model)
```

**Option 2: WebRTC VAD**

```python
# Install
pip install webrtcvad

# Usage
import webrtcvad
vad = webrtcvad.Vad(3)  # Aggressiveness 0-3
is_speech = vad.is_speech(frame, sample_rate)
```

---

## üìä SO S√ÅNH ƒê·∫∂C ƒêI·ªÇM

| Feature | Core Processor | Advanced Processor |
|---------|---------------|-------------------|
| **Transcription** | ‚úÖ Whisper | ‚úÖ Whisper |
| **Sentence detection** | ‚úÖ Regex pattern | ‚úÖ Regex pattern |
| **VAD** | ‚ùå | ‚úÖ Pydub silence detection |
| **Audio normalization** | ‚ùå | ‚úÖ Pydub effects |
| **Silence detection** | ‚ùå | ‚úÖ detect_nonsilent() |
| **Split on silence** | ‚ùå | ‚úÖ split_on_silence() |
| **Export formats** | JSON, SRT | JSON, SRT, TXT, CSV |
| **Batch processing** | Manual | ‚úÖ Built-in |
| **Statistics** | Basic | ‚úÖ Detailed |
| **Command line** | ‚úÖ Built-in | ‚ùå Need wrapper |
| **Complexity** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

---

## üî¨ TH∆Ø VI·ªÜN DEPENDENCIES

### Core Processor

```txt
openai-whisper    # Transcription
pydub            # Basic audio manipulation
yt-dlp           # YouTube download
torch            # Whisper backend
torchaudio       # Audio processing
numpy            # Math operations
```

### Advanced Processor (Th√™m)

```txt
# Advanced th·ª´a k·∫ø t·∫•t c·∫£ dependencies c·ªßa Core
# PLUS kh√¥ng c√≥ g√¨ th√™m! V·∫´n d√πng pydub

# Nh∆∞ng s·ª≠ d·ª•ng advanced features c·ªßa pydub:
pydub.silence    # VAD functions
pydub.effects    # Normalization
```

**K·∫øt lu·∫≠n:** Advanced processor KH√îNG d√πng th∆∞ vi·ªán b·ªï sung, ch·ªâ d√πng advanced features c·ªßa Pydub!

---

## üí° KHI N√ÄO D√ôNG ADVANCED?

### D√πng Core Processor khi:
- ‚úÖ Ch·ªâ c·∫ßn transcription + t√°ch c√¢u
- ‚úÖ Mu·ªën command line ƒë∆°n gi·∫£n
- ‚úÖ Kh√¥ng c·∫ßn VAD
- ‚úÖ Ch·ªâ c·∫ßn JSON + SRT

### D√πng Advanced Processor khi:
- ‚úÖ C·∫ßn Voice Activity Detection
- ‚úÖ Audio c√≥ nhi·ªÅu silence c·∫ßn lo·∫°i b·ªè
- ‚úÖ C·∫ßn normalize audio t·ª´ nhi·ªÅu ngu·ªìn
- ‚úÖ C·∫ßn export TXT, CSV
- ‚úÖ C·∫ßn statistics chi ti·∫øt
- ‚úÖ Batch processing nhi·ªÅu files

---

## üéØ QUICK EXAMPLES

### Core Processor (Command Line):

```powershell
# ƒê∆°n gi·∫£n - c√≥ s·∫µn CLI
python audio_video_processor.py audio.mp3 --model small --device cuda
```

### Advanced Processor (Need Wrapper):

```powershell
# T·∫°o wrapper tr∆∞·ªõc
# File: run_advanced.py (copy code ·ªü tr√™n)

# Sau ƒë√≥ ch·∫°y
python run_advanced.py audio.mp3 --model small --device cuda --vad --normalize
```

### Advanced Processor (Python Code - Recommended):

```python
# C√°ch t·ªët nh·∫•t cho advanced
from advanced_processor import AdvancedAudioProcessor

processor = AdvancedAudioProcessor(model_size="small", device="cuda")

result = processor.process_advanced(
    "audio.mp3",
    use_vad=True,
    normalize=True,
    export_formats=['json', 'srt', 'txt', 'csv']
)
```

---

## ‚úÖ SUMMARY

### Advanced Processor ƒë·∫∑c bi·ªát ·ªü:

1. **VAD (Voice Activity Detection)**
   - Library: `pydub.silence`
   - Method: Amplitude-based
   - Functions: `detect_nonsilent()`, `split_on_silence()`

2. **Audio Normalization**
   - Library: `pydub.effects`
   - Method: dBFS normalization

3. **Advanced exports**
   - TXT, CSV th√™m v√†o JSON, SRT

4. **Batch processing**
   - Built-in batch function

5. **Statistics**
   - Detailed audio statistics

### ƒê·ªÉ ch·∫°y t·ª´ terminal:

1. ‚ùå Kh√¥ng c√≥ built-in CLI
2. ‚úÖ T·∫°o wrapper script (code ·ªü tr√™n)
3. ‚úÖ Ho·∫∑c d√πng Python code tr·ª±c ti·∫øp (recommended)

---

## üìÅ FILES C·∫¶N T·∫†O

Download v√† t·∫°o c√°c file:

1. **[advanced_processor.py](computer:///mnt/user-data/outputs/advanced_processor.py)** - Main advanced processor
2. **[run_advanced.py](computer:///mnt/user-data/outputs/run_advanced.py)** - NEW wrapper script (will create)

---

**Last updated:** November 26, 2024  
**VAD Library:** Pydub.silence (amplitude-based)  
**Not using:** ML-based VAD models
